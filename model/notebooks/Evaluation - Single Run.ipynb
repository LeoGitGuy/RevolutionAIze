{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#Basic Imports\n",
    "import os,sys\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from tqdm import tqdm,trange\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "\n",
    "from datasets.ssl_dataset import SSL_Dataset\n",
    "from datasets.data_utils import get_data_loader\n",
    "from utils import get_model_checkpoints\n",
    "from utils import net_builder\n",
    "from utils import plot_examples, plot_cmatrix\n",
    "\n",
    "import pandas as pd\n",
    "from termcolor import colored\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eurosat_rgb_path=\"/scratch/fixmatch_results/new_runs/nr_of_labels/eurosat_rgb/FixMatch_archefficientnet-b2_batch32_confidence0.95_lr0.03_uratio7_wd0.00075_wu1.0_seed0_numlabels50_optSGD\"\n",
    "ucm_path = \"/scratch/fixmatch_results/runs_new_paper_version/nr_of_labels/ucm/FixMatch_archefficientnet-b2_batch16_confidence0.95_lr0.03_uratio4_wd0.00075_wu1.0_seed0_numlabels105_optSGD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_all_seeds=True\n",
    "path = eurosat_rgb_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints, args = get_model_checkpoints(path)\n",
    "args = args[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"batch_size\"] = 256\n",
    "args[\"data_dir\"] = \"./data/\"\n",
    "args[\"use_train_model\"] = False\n",
    "args[\"load_path\"] = checkpoints[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(args[\"load_path\"])\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "load_model = (checkpoint[\"train_model\"] if args[\"use_train_model\"] else checkpoint[\"eval_model\"])\n",
    "\n",
    "_eval_dset = SSL_Dataset(name=args[\"dataset\"], train=False, data_dir=args[\"data_dir\"], seed=args[\"seed\"])\n",
    "eval_dset = _eval_dset.get_dset()\n",
    "\n",
    "_net_builder = net_builder(args[\"net\"],None,{})\n",
    "\n",
    "net = _net_builder(num_classes=_eval_dset.num_classes, in_channels=_eval_dset.num_channels)\n",
    "net.load_state_dict(load_model)\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()\n",
    "net.eval()\n",
    "\n",
    "\n",
    "\n",
    "eval_loader = get_data_loader(eval_dset, args[\"batch\"], num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoding = _eval_dset.label_encoding\n",
    "inv_transf = _eval_dset.inv_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_examples(eval_dset.data,eval_dset.targets,label_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assemble a batch\n",
    "images, labels, preds = [],[],[]\n",
    "with torch.no_grad():\n",
    "    for image, target in tqdm(eval_loader):\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "        logit = net(image)\n",
    "        for idx,img in enumerate(image):\n",
    "            images.append(inv_transf(img.transpose(0,2).cpu().numpy()).transpose(0,2).numpy())\n",
    "        preds.append(logit.cpu().max(1)[1])\n",
    "        labels.append(target)\n",
    "labels = torch.cat(labels).numpy()\n",
    "preds = torch.cat(preds).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_examples(images,labels,label_encoding, (10,6), 160, 6,preds, args[\"dataset\"]+\".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate all test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_all_seeds:\n",
    "    labels, preds = [],[]\n",
    "    \n",
    "    for seed in [0,1,2]:\n",
    "        \n",
    "        print(\"Processing seed:\", colored(seed,\"red\"))\n",
    "        checkpoint_path=checkpoints[0].replace(\"seed\"+str(checkpoints[0][checkpoints[0].find(\"seed\")+4]), \"seed\"+str(seed))\n",
    "        print(checkpoint_path)\n",
    "        \n",
    "        checkpoint = torch.load(checkpoint_path,map_location='cuda:0')\n",
    "        load_model = (checkpoint[\"train_model\"] if args[\"use_train_model\"] else checkpoint[\"eval_model\"])\n",
    "        _net_builder = net_builder(args[\"net\"],False,{})\n",
    "        _eval_dset = SSL_Dataset(name=args[\"dataset\"], train=False, data_dir=args[\"data_dir\"], seed=seed)\n",
    "        eval_dset = _eval_dset.get_dset()\n",
    "        net = _net_builder(num_classes=_eval_dset.num_classes, in_channels=_eval_dset.num_channels)\n",
    "        net.load_state_dict(load_model)\n",
    "        if torch.cuda.is_available():\n",
    "            net.cuda()\n",
    "        net.eval()\n",
    "        eval_loader = get_data_loader(eval_dset, args[\"batch\"], num_workers=1)\n",
    "        \n",
    "        #Assemble a batch\n",
    "        labels_seed, preds_seed = [],[]\n",
    "        with torch.no_grad():\n",
    "            for image, target in tqdm(eval_loader):\n",
    "                image = image.type(torch.FloatTensor).cuda()\n",
    "                logit = net(image)\n",
    "                \n",
    "                preds_seed.append(logit.cpu().max(1)[1])\n",
    "                labels_seed.append(target)\n",
    "                \n",
    "        preds.append(torch.cat(preds_seed).numpy())\n",
    "        labels.append(torch.cat(labels_seed).numpy())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_all_seeds:\n",
    "    test_report_list=[]\n",
    "    for labels_seed, preds_seed in zip(labels, preds):\n",
    "        test_seed=classification_report(labels_seed, preds_seed, target_names=label_encoding, output_dict=True)\n",
    "        test_seed_keys=list(test_seed.keys())[:-3]\n",
    "        test_seed_values=list(test_seed.values())[:-3]\n",
    "        test_report_list.append(dict(zip(test_seed_keys, test_seed_values)))\n",
    "        test_report_keys=list(test_report_list[0].keys())\n",
    "    test_report=deepcopy(test_report_list[0])\n",
    "    \n",
    "    for key in list(test_report_keys):\n",
    "        test_report[key]['precision']=0.0\n",
    "        test_report[key]['recall']=0.0\n",
    "        test_report[key]['f1-score']=0.0\n",
    "        test_report[key]['support']=0.0\n",
    "    \n",
    "    for key in list(test_report_keys):\n",
    "        for n in range(len(test_report_list)):\n",
    "            test_report[key]['precision']+=test_report_list[n][key]['precision']/len(test_report_list)\n",
    "            test_report[key]['recall']+=test_report_list[n][key]['recall']/len(test_report_list)\n",
    "            test_report[key]['f1-score']+=test_report_list[n][key]['f1-score']/len(test_report_list)\n",
    "            test_report[key]['support']+=test_report_list[n][key]['support']/len(test_report_list)\n",
    "\n",
    "        \n",
    "else:\n",
    "    test_report = classification_report(labels, preds, target_names=label_encoding, output_dict=True)[:-3]\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(test_report)\n",
    "print(df)\n",
    "df.to_csv(\"./\"+str(args[\"dataset\"])+\"_\"+str(args[\"numlabels\"]) + \"_test_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cmatrix(preds,labels,label_encoding, figsize=(10, 8),dpi=150, class_names_font_scale=1.6, matrix_font_size=12, save_fig_name=str(args[\"dataset\"])+\"_\"+str(args[\"numlabels\"])+\"_cm.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
