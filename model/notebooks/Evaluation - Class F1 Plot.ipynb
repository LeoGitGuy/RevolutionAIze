{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#Basic Imports\n",
    "import os,sys\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from tqdm import tqdm,trange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report,confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from datasets.ssl_dataset import SSL_Dataset\n",
    "from datasets.data_utils import get_data_loader\n",
    "from utils import get_model_checkpoints\n",
    "from utils import net_builder\n",
    "from utils import clean_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_folder = \"/home/gabrielemeoni/project/SSLRS\" #Path where tmp csv files are stored\n",
    "folder = \"/scratch/fixmatch_results/new_runs/nr_of_labels/eurosat_rgb\" #Path to the runs to load \n",
    "sort_criterion = \"numlabels\" # Accepted net, numlabels\n",
    "seed_wanted = [0,1,2] # Seed wanted (the others will be filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints, run_args = get_model_checkpoints(folder)\n",
    "if os.name == 'nt':\n",
    "       [print(_.split(\"\\\\\")[1]) for _ in checkpoints];\n",
    "else:\n",
    "       [print(_.split(\"/\")[1]) for _ in checkpoints];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for checkpoint, args in zip(checkpoints,run_args):\n",
    "    print(\"------------ RUNNING \", checkpoint, \" -----------------\")\n",
    "    print(args)\n",
    "    args[\"batch_size\"] = 256\n",
    "    args[\"data_dir\"] = \"./data/\"\n",
    "    args[\"use_train_model\"] = False\n",
    "    args[\"load_path\"] = checkpoint\n",
    "    if args[\"seed\"] in seed_wanted:\n",
    "        checkpoint_path = os.path.join(args[\"load_path\"])\n",
    "        checkpoint = torch.load(checkpoint_path,map_location='cuda:0')\n",
    "        load_model = (checkpoint[\"train_model\"] if args[\"use_train_model\"] else checkpoint[\"eval_model\"])\n",
    "        _net_builder = net_builder(args[\"net\"],False,{})\n",
    "        _eval_dset = SSL_Dataset(name=args[\"dataset\"], train=False, data_dir=args[\"data_dir\"], seed=args[\"seed\"])\n",
    "        eval_dset = _eval_dset.get_dset()\n",
    "        net = _net_builder(num_classes=_eval_dset.num_classes, in_channels=_eval_dset.num_channels)\n",
    "        net.load_state_dict(load_model)\n",
    "        if torch.cuda.is_available():\n",
    "            net.cuda()\n",
    "        net.eval()\n",
    "     \n",
    "        eval_loader = get_data_loader(eval_dset, args[\"batch_size\"], num_workers=1)\n",
    "        label_encoding = _eval_dset.label_encoding\n",
    "        inv_transf = _eval_dset.inv_transform\n",
    "    \n",
    "        \n",
    "        print(\"------------ PREDICTING TESTSET -----------------\")\n",
    "        \n",
    "        images, labels, preds = [],[],[]\n",
    "        with torch.no_grad():\n",
    "            for image, target in tqdm(eval_loader):\n",
    "                image = image.type(torch.FloatTensor).cuda()\n",
    "                logit = net(image)\n",
    "                for idx,img in enumerate(image):\n",
    "                    images.append(inv_transf(img.transpose(0,2).cpu().numpy()).transpose(0,2).numpy())\n",
    "                preds.append(logit.cpu().max(1)[1])\n",
    "                labels.append(target)\n",
    "        labels = torch.cat(labels).numpy()\n",
    "        preds = torch.cat(preds).numpy()\n",
    "        test_report = classification_report(labels, preds, target_names=label_encoding, output_dict=True)\n",
    "        test_report[\"params\"] = args\n",
    "        results.append(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = pd.DataFrame()\n",
    "pd.set_option('display.max_columns', None)\n",
    "for result in results:\n",
    "    params = result[\"params\"]\n",
    "    df = pd.DataFrame(result)\n",
    "    df.drop(list(params.keys()),inplace=True)\n",
    "    df.drop([\"support\",\"recall\",\"precision\"],inplace=True)\n",
    "    for key,val in params.items():\n",
    "        df[key] = val\n",
    "    df = df.set_index(\"dataset\")\n",
    "    big_df = big_df.append(df)\n",
    "# print(big_df)\n",
    "small_df = clean_results_df(big_df, folder,sort_criterion, keep_per_class=True)\n",
    "small_df.to_csv(csv_folder + \"_test_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small_df = pd.read_csv(csv_folder + \"_test_results.csv\")\n",
    "small_df = small_df.drop(labels=[\"pretrained\",\"supervised\",\"net\",\"accuracy\",\"batch\",\"confidence\",\"lr\",\"uratio\",\"wd\",\"wu\",\"opt\",\"iterations\",\"load_path\"],axis=1)\n",
    "small_df = small_df.groupby('numlabels').mean().reset_index()\n",
    "# small_df = small_df.set_index(\"numlabels\")\n",
    "small_df = small_df.reindex(sorted(small_df.columns), axis=1)\n",
    "small_df = small_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names_dict={'eurosat_rgb' : ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway',\n",
    "       'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River',\n",
    "       'SeaLake'], 'eurosat_ms' : ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway',\n",
    "       'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River',\n",
    "       'SeaLake'], 'ucm' : [\"agricultural\", \"airplane\", \"baseballdiamond\", \"beach\", \"buildings\",\"chaparral\",\"denseresidential\",\"forest\", \"freeway\", \"golfcourse\",\"harbor\", \"intersection\", \"mediumresidential\", \"mobilehomepark\",\"overpass\",\"parkinglot\",\"river\", \"runway\", \"sparseresidential\", \"storagetanks\", \"tenniscourt\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding info on numlabels per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(small_df[\"numlabels\"])):\n",
    "    small_df[\"numlabels\"][n]=str(small_df[\"numlabels\"][n]) + \" (\" + str(small_df[\"numlabels\"][n]//len(class_names_dict[args['dataset']]))+\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = pd.melt(small_df, id_vars='numlabels', value_vars=class_names_dict[args['dataset']])\n",
    "l.columns = [\"# of labels \\n(per class)\", \"Class\", \"F1 Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.loc[l[\"Class\"]==\"denseresidential\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "sns.set()\n",
    "sns.set(font_scale=3)  # crazy big\n",
    "with sns.plotting_context():\n",
    "    p = sns.catplot(x=\"F1 Score\", y=\"Class\", hue=\"# of labels \\n(per class)\", data=l, kind=\"bar\",palette=\"crest\",height=10,aspect=1.25)\n",
    "    # p.set_xticklabels(rotation=90)\n",
    "    p.set(xlim=[0.3,1.01])\n",
    "\n",
    "    # p.set(xticks=[0.4,0.6,0.8,1.0])\n",
    "plt.savefig(\"class_f1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.loc[l[\"Class\"]==l[\"Class\"][26]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.loc[l[\"Class\"]==\"mediumresidential\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
